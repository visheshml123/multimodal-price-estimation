{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a0676-3364-4b2f-9a8a-310d834cb8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT: final_prediction_pipeline.py - FINAL VERSION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Configuration & Paths ---\n",
    "# !!! IMPORTANT: VERIFY THESE PATHS MATCH YOUR LOCAL SETUP !!!\n",
    "TEST_CSV_PATH = '/Users/visheshbishnoi/Desktop/amazon/code/test_with_engineered_features.csv'  # Test CSV path\n",
    "TEST_TEXT_EMBEDDINGS_PATH = '/Users/visheshbishnoi/Desktop/amazon/code/test_text_embeddings_CUSTOM.npy'\n",
    "TEST_IMG_EMBEDDINGS_PATH = '/Users/visheshbishnoi/Desktop/amazon/code/test_image_embeddings_siglip_with_id (1).npy'\n",
    "SUBMISSION_FILE_PATH = 'test_out1.csv'  # Final output CSV name\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- Model & Transformer Paths ---\n",
    "# NOTE: Removed invisible U+00A0 characters from this block to fix SyntaxError\n",
    "BASE_MODEL_PATHS = {\n",
    "    'lgbm': 'final_model_lgbm.joblib',\n",
    "    'xgb': 'final_model_xgb.joblib',\n",
    "    'cat': 'final_model_cat.joblib',\n",
    "    'mlp_state': 'final_model_mlp.pt',\n",
    "    'mlp_scaler': 'final_scaler_nn.joblib'\n",
    "}\n",
    "META_MODEL_PATH = 'final_meta_model.joblib' \n",
    "\n",
    "TRANSFORMER_PATHS = {\n",
    "    'text_pca': 'final_text_pca.joblib',\n",
    "    'img_pca': 'final_img_pca.joblib',\n",
    "    'label_encoders': 'final_label_encoders.joblib'\n",
    "}\n",
    "\n",
    "numerical_features = ['value', 'ipq', 'value_per_item', 'is_organic', 'is_sugar_free', 'is_premium_keyword',\n",
    "    'is_dietary_specific']\n",
    "categorical_features = ['unit_standardized', 'brand_cleaned']\n",
    "\n",
    "\n",
    "# --- PyTorch MLP Model Definition (MUST be identical to training) ---\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X): self.X = torch.tensor(X, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx]\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1))\n",
    "    def forward(self, x): return self.model(x).squeeze(-1)\n",
    "\n",
    "\n",
    "def generate_submission():\n",
    "    print(\"--- Starting Final Prediction Pipeline ---\")\n",
    "\n",
    "    # --- 1. Load Data and Saved Components ---\n",
    "    print(\"Loading Data and Saved Objects...\")\n",
    "    try:\n",
    "        test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "        original_test_ids = test_df['sample_id']\n",
    "\n",
    "        test_text_embed = np.load(TEST_TEXT_EMBEDDINGS_PATH)\n",
    "        test_img_embed_data = np.load(TEST_IMG_EMBEDDINGS_PATH, allow_pickle=True)\n",
    "        id_to_img_embedding_map = {item['sample_id']: item['embedding'] for item in test_img_embed_data if isinstance(item, dict) and 'sample_id' in item and 'embedding' in item}\n",
    "    \n",
    "        if id_to_img_embedding_map:\n",
    "            # Use the shape of the first loaded image embedding\n",
    "            IMG_EMBEDDING_DIM = next(iter(id_to_img_embedding_map.values())).shape[0]\n",
    "        else:\n",
    "            # Fallback if map is empty\n",
    "            IMG_EMBEDDING_DIM = 768 # Default SigLIP/CLIP dimension\n",
    "            print(f\"Warning: Image embedding map is empty. Using default IMG_EMBEDDING_DIM={IMG_EMBEDDING_DIM}\")\n",
    "\n",
    "        # This line now uses the correct IMG_EMBEDDING_DIM for alignment/padding\n",
    "        aligned_img_embed = np.array([id_to_img_embedding_map.get(sid, np.zeros(IMG_EMBEDDING_DIM)) for sid in test_df['sample_id']])\n",
    " \n",
    "\n",
    "        # Load transformers and models\n",
    "        text_pca = joblib.load(TRANSFORMER_PATHS['text_pca'])\n",
    "        img_pca = joblib.load(TRANSFORMER_PATHS['img_pca'])\n",
    "        le_encoders = joblib.load(TRANSFORMER_PATHS['label_encoders'])\n",
    "        mlp_scaler = joblib.load(BASE_MODEL_PATHS['mlp_scaler'])\n",
    "        \n",
    "        final_meta_model = joblib.load(META_MODEL_PATH)\n",
    "        final_model_lgbm = joblib.load(BASE_MODEL_PATHS['lgbm'])\n",
    "        final_model_xgb = joblib.load(BASE_MODEL_PATHS['xgb'])\n",
    "        final_model_cat = joblib.load(BASE_MODEL_PATHS['cat'])\n",
    "\n",
    "        mlp_input_size = text_pca.n_components + img_pca.n_components + len(le_encoders) + len(numerical_features)\n",
    "        final_model_mlp = MLPModel(mlp_input_size).to(DEVICE)\n",
    "        final_model_mlp.load_state_dict(torch.load(BASE_MODEL_PATHS['mlp_state'], map_location=DEVICE))\n",
    "        final_model_mlp.eval()\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Required file not found: {e}\")\n",
    "        print(\"Please ensure all model and transformer files are in the current directory.\")\n",
    "        return\n",
    "    \n",
    "    print(\" All data and objects loaded successfully.\")\n",
    "    \n",
    "    # --- 2. Test Data Preprocessing (Using TRAIN-fitted transformers) ---\n",
    "    print(\"\\n--- Preprocessing Test Data ---\")\n",
    "    \n",
    "    # Imputation \n",
    "    for col in numerical_features:\n",
    "        test_df[col] = test_df[col].fillna(test_df[col].median()) \n",
    "        \n",
    "    test_numerical_df = test_df[numerical_features]\n",
    "    test_categorical_df = test_df[categorical_features].fillna('unknown').astype(str)\n",
    "\n",
    "    # Apply PCA (using fitted transformers)\n",
    "    test_text_pca = text_pca.transform(test_text_embed)\n",
    "    test_img_pca = img_pca.transform(aligned_img_embed)\n",
    "\n",
    "    # Apply Label Encoding (Handling unseen labels)\n",
    "    print(\"Applying Label Encoding (handling unseen labels)...\")\n",
    "    test_categorical_le_list = []\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        le = le_encoders[col]\n",
    "        \n",
    "        # Create mapping from fitted classes\n",
    "        le_mapping = {label: i for i, label in enumerate(le.classes_)}\n",
    "        \n",
    "        # Assign the unknown value (one greater than the max encoded value)\n",
    "        unknown_value = len(le.classes_) \n",
    "        \n",
    "        # Apply mapping using lambda function: map known labels, assign unknown_value to new labels\n",
    "        encoded_col = test_categorical_df[col].apply(lambda x: le_mapping.get(x, unknown_value)).values.reshape(-1, 1)\n",
    "        \n",
    "        test_categorical_le_list.append(encoded_col)\n",
    "        \n",
    "    test_categorical_le = np.hstack(test_categorical_le_list)\n",
    "\n",
    "    # Combine all features for tree models and for NN scaling\n",
    "    X_test_full = pd.concat([pd.DataFrame(test_numerical_df.values), \n",
    "                             pd.DataFrame(test_categorical_le),\n",
    "                             pd.DataFrame(test_text_pca), \n",
    "                             pd.DataFrame(test_img_pca)], axis=1)\n",
    "    X_test_full.columns = [str(i) for i in range(X_test_full.shape[1])]\n",
    "    print(f\"Final test feature matrix shape: {X_test_full.shape}\")\n",
    "\n",
    "    # --- 3. Level 1: Generate 4 Base Predictions (Meta-Features) ---\n",
    "    print(\"\\n--- Level 1: Generating 4 Base Predictions (Log-Price) ---\")\n",
    "    meta_features_test = pd.DataFrame()\n",
    "\n",
    "    # Tree Models\n",
    "    meta_features_test['lgbm_pred'] = final_model_lgbm.predict(X_test_full)\n",
    "    meta_features_test['xgb_pred'] = final_model_xgb.predict(X_test_full)\n",
    "    meta_features_test['cat_pred'] = final_model_cat.predict(X_test_full)\n",
    "\n",
    "    # MLP (NN)\n",
    "    X_test_nn = mlp_scaler.transform(X_test_full.values) # Use saved StandardScaler\n",
    "    test_loader = DataLoader(TabularDataset(X_test_nn), batch_size=256, shuffle=False)\n",
    "    mlp_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X in test_loader:\n",
    "            outputs = final_model_mlp(batch_X.to(DEVICE))\n",
    "            mlp_preds.extend(outputs.cpu().numpy())\n",
    "    meta_features_test['mlp_pred'] = np.array(mlp_preds)\n",
    "    \n",
    "    print(f\"Meta-features (Level 1 Predictions) shape: {meta_features_test.shape}\")\n",
    "\n",
    "    # --- 4. Level 2: Final Prediction using Meta-Model ---\n",
    "    print(\"\\n--- Level 2: Applying LightGBM Stacker (Final Log-Price Prediction) ---\")\n",
    "    # The meta-model predicts the final log-transformed price\n",
    "    final_log_price_preds = final_meta_model.predict(meta_features_test)\n",
    "\n",
    "    # --- 5. Reverse Transformation and Submission ---\n",
    "    # Convert from log-transformed price back to actual price: price = exp(log_price) - 1 (np.expm1)\n",
    "    final_price_preds = np.expm1(final_log_price_preds)\n",
    "\n",
    "    # Clip negative predictions to 0 (since price cannot be negative)\n",
    "    final_price_preds[final_price_preds < 0] = 0 \n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        'sample_id': original_test_ids,\n",
    "        'price': final_price_preds\n",
    "    })\n",
    "\n",
    "    submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"**Final Submission File Created Successfully!**\")\n",
    "    print(f\"File: {SUBMISSION_FILE_PATH}\")\n",
    "    print(f\"Total predictions made: {len(submission_df)}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_submission()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
