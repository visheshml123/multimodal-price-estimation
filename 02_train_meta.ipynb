{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264924b-a3b4-47c3-9120-713043392ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 2: train_meta_model.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "print(\"--- Starting Meta-Model Training and Evaluation ---\")\n",
    "\n",
    "# --- SMAPE Metric ---\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "# --- ‚öôÔ∏è Configuration ---\n",
    "TRAIN_CSV_PATH = 'train_final.csv'\n",
    "OOF_PATHS = {\n",
    "    'lgbm': 'oof_lgbm_preds.npy',\n",
    "    'xgb': 'oof_xgb_preds.npy',\n",
    "    'cat': 'oof_cat_preds.npy',\n",
    "    'mlp': 'oof_mlp_preds.npy'\n",
    "}\n",
    "FINAL_META_MODEL_PATH = 'final_meta_model.joblib'\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading OOF predictions and true target values...\")\n",
    "meta_features = pd.DataFrame()\n",
    "for name, path in OOF_PATHS.items():\n",
    "    try:\n",
    "        meta_features[f'{name}_pred'] = np.load(path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Prediction file not found at '{path}'. Please run the base model script first.\")\n",
    "        exit()\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "\n",
    "# --- FIX: Add this block to handle both 'price_log' and 'log_price' ---\n",
    "if 'log_price' not in train_df.columns and 'price_log' in train_df.columns:\n",
    "    train_df.rename(columns={'price_log': 'log_price'}, inplace=True)\n",
    "# --- END FIX ---\n",
    "\n",
    "is_valid_mask = train_df['log_price'].notna()\n",
    "meta_target = train_df[is_valid_mask]['log_price'].values\n",
    "y_true_price = np.expm1(meta_target)\n",
    "print(f\"Meta-features created with shape: {meta_features.shape}\")\n",
    "assert len(meta_features) == len(meta_target), \"Mismatch between OOF predictions and target length.\"\n",
    "\n",
    "# --- 2. Evaluate Blending and Stacking ---\n",
    "print(\"\\n--- Evaluating Simple Blending ---\")\n",
    "blend_preds_log = meta_features.mean(axis=1).values\n",
    "blend_score = smape(y_true_price, np.expm1(blend_preds_log))\n",
    "\n",
    "print(\"\\n--- Evaluating Stacking with RidgeCV ---\")\n",
    "meta_model_ridge = RidgeCV(alphas=np.logspace(-4, 2, 100), cv=5)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_ridge_preds = np.zeros(len(meta_features))\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(meta_features)):\n",
    "    X_train_meta, X_val_meta = meta_features.iloc[train_idx], meta_features.iloc[val_idx]\n",
    "    y_train_meta = meta_target[train_idx]\n",
    "    meta_model_ridge.fit(X_train_meta, y_train_meta)\n",
    "    oof_ridge_preds[val_idx] = meta_model_ridge.predict(X_val_meta)\n",
    "ridge_score = smape(y_true_price, np.expm1(oof_ridge_preds))\n",
    "\n",
    "print(\"\\n--- Evaluating Stacking with LightGBM ---\")\n",
    "lgbm_meta_params = {\n",
    "    'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 1000,\n",
    "    'learning_rate': 0.01, 'num_leaves': 16, 'verbose': -1, 'n_jobs': -1, 'seed': 42\n",
    "}\n",
    "meta_model_lgbm = lgb.LGBMRegressor(**lgbm_meta_params)\n",
    "oof_lgbm_meta_preds = np.zeros(len(meta_features))\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(meta_features)):\n",
    "    X_train_meta, X_val_meta = meta_features.iloc[train_idx], meta_features.iloc[val_idx]\n",
    "    y_train_meta, y_val_meta = meta_target[train_idx], meta_target[val_idx]\n",
    "    meta_model_lgbm.fit(X_train_meta, y_train_meta, \n",
    "                        eval_set=[(X_val_meta, y_val_meta)],\n",
    "                        callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "    oof_lgbm_meta_preds[val_idx] = meta_model_lgbm.predict(X_val_meta)\n",
    "lgbm_stack_score = smape(y_true_price, np.expm1(oof_lgbm_meta_preds))\n",
    "\n",
    "# --- 3. Train and Save the Final (Best) Meta-Model ---\n",
    "print(\"\\n--- Training the Final LightGBM Meta-Model on ALL OOF Data ---\")\n",
    "final_meta_model = lgb.LGBMRegressor(**lgbm_meta_params)\n",
    "final_meta_model.fit(meta_features, meta_target)\n",
    "joblib.dump(final_meta_model, FINAL_META_MODEL_PATH)\n",
    "print(f\"Final meta-model (LightGBM) saved successfully to '{FINAL_META_MODEL_PATH}'\")\n",
    "\n",
    "# --- 4. Final Results ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Final Ensemble Performance üöÄ\")\n",
    "print(f\"Simple Blending SMAPE Score:      {blend_score:.4f}\")\n",
    "print(f\"Stacking (RidgeCV) SMAPE Score:   {ridge_score:.4f}\")\n",
    "print(f\"Stacking (LightGBM) SMAPE Score:  {lgbm_stack_score:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
